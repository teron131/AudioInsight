---
description: 
globs: 
alwaysApply: true
---
# AudioInsight Project Structure

## Package Organization
The project follows a specific structure with the backend package and optional frontend UI:

```
AudioInsight/
├── audioinsight/               # Backend package
│   ├── __init__.py
│   ├── app.py                 # Main entry point
│   ├── config.py              # Configuration
│   ├── processors.py          # Core logic with event-based LLM integration
│   ├── diarization/           # Speaker identification modules
│   ├── server/                # Server components  
│   ├── whisper_streaming/     # Real-time audio processing
│   └── llm/                   # Event-based LLM processing system
│       ├── base.py            # EventBasedProcessor & shared executor
│       ├── parser.py          # Concurrent text parsing (3 workers)
│       ├── summarizer.py      # Concurrent summarization (2 workers)
│       ├── types.py           # LLM data structures & configuration
│       └── utils.py           # LLM utilities & helpers
├── audioinsight-ui/           # Frontend (if applicable)
├── audio/                     # Audio input directory
├── logs/                      # Application logs
├── setup.py                   # Package setup
├── start.sh                   # Backend startup script
├── package.json               # Root coordination
└── .env                       # Environment variables
```

Reference key files:
- Main entry point: [audioinsight/app.py](mdc:audioinsight/app.py)
- Configuration: [audioinsight/config.py](mdc:audioinsight/config.py)
- Backend startup: [start.sh](mdc:start.sh)
- Package setup: [setup.py](mdc:setup.py)
- Event-based LLM foundation: [audioinsight/llm/base.py](mdc:audioinsight/llm/base.py)

## Development Setup
Install the package in development mode:
```bash
pip install -e .
```

This allows importing from anywhere:
```python
from audioinsight.processors import AudioProcessor
from audioinsight.llm import LLMSummarizer, Parser
```

## Full-Stack Development Commands

### Main Directory Coordination
The root [package.json](mdc:package.json) contains proxy commands that delegate to the frontend package:

```bash
# Start both frontend + backend simultaneously
npm run dev

# Individual services
./start.sh              # Backend only
cd audioinsight-ui && npm run dev:frontend  # Frontend only
```

### How It Works
- Main [package.json](mdc:package.json) proxies to frontend
- Frontend package.json uses `concurrently` to run both services
- Backend started via [start.sh](mdc:start.sh) script

## Module Organization Rules

### Standalone Modules
Place in dedicated directories under `audioinsight/`:
- `diarization/` - Speaker diarization functionality
- `whisper_streaming/` - Real-time audio processing
- `server/` - Server-specific components
- `llm/` - **Event-based LLM processing system** with concurrent workers

### Core Files
- `app.py` - FastAPI application and main entry point
- `config.py` - Centralized configuration management
- `processors.py` - Core audio processing logic with LLM coordination

### LLM Architecture (New Event-Based System)
The `llm/` module implements high-performance concurrent processing:

#### **Core Components**
- **`base.py`**: EventBasedProcessor abstract class with shared thread pool
- **`parser.py`**: Real-time text correction with 3 concurrent workers
- **`summarizer.py`**: Conversation analysis with 2 concurrent workers  
- **`types.py`**: Type definitions and configuration classes
- **`utils.py`**: Utility functions and helpers

#### **Performance Features**
- **Shared Thread Pool**: Single executor reused across all LLM operations (90% overhead reduction)
- **Concurrent Workers**: Multiple workers processing simultaneously
- **Intelligent Queuing**: Large queues (50-100 items) prevent blocking
- **Optimized Cooldowns**: 0.1s parser, 0.5s summarizer (10x faster than before)
- **Thread-Safe Operations**: Proper concurrent access management

### Import Patterns
Use relative imports within the audioinsight package:
```python
# From audioinsight/app.py
from .config import config
from .processors import AudioProcessor
from .diarization.speaker_diarization import DiarizationProcessor

# Event-based LLM imports
from .llm.base import EventBasedProcessor, UniversalLLM
from .llm.parser import Parser  
from .llm.summarizer import LLMSummarizer
from .llm.types import LLMConfig, LLMTrigger, ParsedTranscript
```

## Event-Based Architecture Integration

### **AudioProcessor Coordination**
The main `AudioProcessor` coordinates all components including event-based LLM workers:

```python
# From audioinsight/processors.py
class AudioProcessor:
    def __init__(self):
        # Initialize LLM components with event-based processing
        self.llm = LLMSummarizer()  # 2 concurrent workers
        self.transcript_parser = Parser()  # 3 concurrent workers
        
    async def create_tasks(self):
        # Start LLM worker pools
        if self.llm:
            await self.llm.start_monitoring()
        if self.transcript_parser:
            await self.transcript_parser.start_worker()
```

### **Performance Monitoring**
Components provide detailed status monitoring:
```python
# Get real-time performance metrics
parser_status = parser.get_queue_status()
# Returns: queue_size, active_workers, max_workers, is_running

llm_stats = llm.get_stats()  
# Returns: processing times, queue metrics, worker status
```

This event-based architecture eliminates the polling bottlenecks that caused lag issues and provides scalable concurrent processing for high-throughput applications.

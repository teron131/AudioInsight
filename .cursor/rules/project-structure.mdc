---
description: 
globs: 
alwaysApply: true
---
# AudioInsight Project Structure

## Package Organization
The project follows a specific structure with the backend package and optional frontend UI:

```
AudioInsight/
├── audioinsight/               # Backend package
│   ├── __init__.py
│   ├── app.py                 # Main entry point
│   ├── config.py              # Configuration
│   ├── processors.py          # Core logic with non-blocking LLM integration
│   ├── diarization/           # Speaker identification modules
│   ├── server/                # Server components  
│   ├── whisper_streaming/     # Real-time audio processing
│   └── llm/                   # Non-blocking event-based LLM processing system
│       ├── base.py            # EventBasedProcessor & shared executor
│       ├── parser.py          # Non-blocking text parsing (2 workers)
│       ├── summarizer.py      # Non-blocking summarization (2 workers)
│       ├── types.py           # LLM data structures & configuration
│       └── utils.py           # LLM utilities & helpers
├── audioinsight-ui/           # Frontend (if applicable)
├── audio/                     # Audio input directory
├── logs/                      # Application logs
├── setup.py                   # Package setup
├── start.sh                   # Backend startup script
├── package.json               # Root coordination
└── .env                       # Environment variables
```

Reference key files:
- Main entry point: [audioinsight/app.py](mdc:audioinsight/app.py)
- Configuration: [audioinsight/config.py](mdc:audioinsight/config.py)
- Backend startup: [start.sh](mdc:start.sh)
- Package setup: [setup.py](mdc:setup.py)
- Non-blocking LLM foundation: [audioinsight/llm/base.py](mdc:audioinsight/llm/base.py)

## Development Setup
Install the package in development mode:
```bash
pip install -e .
```

This allows importing from anywhere:
```python
from audioinsight.processors import AudioProcessor
from audioinsight.llm import Summarizer, Parser
```

## Full-Stack Development Commands

### Main Directory Coordination
The root [package.json](mdc:package.json) contains proxy commands that delegate to the frontend package:

```bash
# Start both frontend + backend simultaneously
npm run dev

# Individual services
./start.sh              # Backend only
cd audioinsight-ui && npm run dev:frontend  # Frontend only
```

### How It Works
- Main [package.json](mdc:package.json) proxies to frontend
- Frontend package.json uses `concurrently` to run both services
- Backend started via [start.sh](mdc:start.sh) script

## Module Organization Rules

### Standalone Modules
Place in dedicated directories under `audioinsight/`:
- `diarization/` - Speaker diarization functionality
- `whisper_streaming/` - Real-time audio processing
- `server/` - Server-specific components
- `llm/` - **Non-blocking event-based LLM processing system** with fire-and-forget workers

### Core Files
- `app.py` - FastAPI application and main entry point
- `config.py` - Centralized configuration management
- `processors.py` - Core audio processing logic with non-blocking LLM coordination

### LLM Architecture (Non-Blocking Event-Based System)
The `llm/` module implements high-performance non-blocking concurrent processing:

#### **Core Components**
- **`base.py`**: EventBasedProcessor abstract class with shared thread pool and fire-and-forget queuing
- **`parser.py`**: Real-time text correction with 2 non-blocking concurrent workers
- **`summarizer.py`**: Conversation analysis with 2 non-blocking concurrent workers  
- **`types.py`**: Type definitions and configuration classes
- **`utils.py`**: Utility functions and helpers

#### **Performance Features**
- **Shared Thread Pool**: Single executor reused across all LLM operations (90% overhead reduction)
- **Non-Blocking Workers**: Multiple workers processing in background without blocking transcription
- **Fire-and-Forget Queuing**: Large queues (75-150 items) with non-blocking puts prevent transcription delays
- **Ultra-Fast Updates**: 0.05s UI updates (20 FPS) for smooth real-time display
- **Exception Isolation**: LLM failures never affect real-time transcription flow

### Import Patterns
Use relative imports within the audioinsight package:
```python
# From audioinsight/app.py
from .config import config
from .processors import AudioProcessor
from .diarization.speaker_diarization import DiarizationProcessor

# Non-blocking LLM imports
from .llm.base import EventBasedProcessor, UniversalLLM
from .llm.parser import Parser  
from .llm.summarizer import Summarizer
from .llm.types import LLMConfig, LLMTrigger, ParsedTranscript
```

## Non-Blocking Event-Based Architecture Integration

### **AudioProcessor Coordination**
The main `AudioProcessor` coordinates all components including non-blocking LLM workers:

```python
# From audioinsight/processors.py
class AudioProcessor:
    def __init__(self):
        # Initialize LLM components with non-blocking processing
        self.llm = Summarizer()  # 2 non-blocking workers
        self.transcript_parser = Parser()  # 2 non-blocking workers
        
    async def create_tasks(self):
        # Start LLM worker pools (non-blocking)
        if self.llm:
            await self.llm.start_monitoring()
        if self.transcript_parser:
            await self.transcript_parser.start_worker()
            
    def update_llm_non_blocking(self, text, speaker_info):
        # Fire-and-forget LLM updates that never block transcription
        if self.llm:
            self.llm.update_transcription(text, speaker_info)  # Returns immediately
```

### **Performance Monitoring**
Components provide detailed status monitoring:
```python
# Get real-time performance metrics
parser_status = parser.get_queue_status()
# Returns: queue_size, active_workers, max_workers, is_running

llm_stats = llm.get_stats()  
# Returns: processing times, queue metrics, worker status
```

This non-blocking event-based architecture eliminates all transcription delays that were caused by blocking LLM operations and provides zero-lag concurrent processing for high-throughput real-time applications.

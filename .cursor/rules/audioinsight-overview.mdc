---
description: 
globs: 
alwaysApply: true
---
# AudioInsight Project Overview

## Project Description
AudioInsight is a comprehensive audio processing platform that provides real-time transcription, speaker diarization, and intelligent analysis of audio content. The project combines advanced AI models with a modern web interface for seamless audio processing workflows featuring simple LLM analysis that integrates cleanly with real-time transcription.

## Key Components

### Backend (Python/FastAPI)
The core backend is located in the `audioinsight/` package:

- **Main Application**: [audioinsight/app.py](mdc:audioinsight/app.py) - FastAPI server with REST and WebSocket endpoints
- **CLI Interface**: [audioinsight/main.py](mdc:audioinsight/main.py) - AudioInsight class and command-line interface
- **Configuration**: [audioinsight/config.py](mdc:audioinsight/config.py) - Centralized configuration management with Pydantic validation
- **Audio Processing**: [audioinsight/processors/](mdc:audioinsight/processors) - Core audio processing logic and Whisper integration
- **Temporal Objects**: [audioinsight/timed_objects.py](mdc:audioinsight/timed_objects.py) - Time-aware data structures (ASRToken, SpeakerSegment)
- **Logging System**: [audioinsight/logging_config.py](mdc:audioinsight/logging_config.py) - Application-wide logging configuration
- **Speaker Diarization**: [audioinsight/diarization/](mdc:audioinsight/diarization) - Speaker identification and separation
- **Streaming**: [audioinsight/whisper_streaming/](mdc:audioinsight/whisper_streaming) - Real-time audio processing with LocalAgreement-2
- **Server Components**: [audioinsight/server/](mdc:audioinsight/server) - Server utilities and helpers
- **Simple LLM Integration**: [audioinsight/llm/](mdc:audioinsight/llm) - Direct async language model features

### Frontend (Next.js/React)
The web interface is located in `audioinsight-ui/`:

- **Modern React-based UI**: Built with Next.js App Router and TypeScript
- **Real-time WebSocket Communication**: Live audio streaming and result display
- **UI Components**: [audioinsight-ui/components/](mdc:audioinsight-ui/components) - Reusable React components with shadcn/ui
- **Custom Hooks**: [audioinsight-ui/hooks/](mdc:audioinsight-ui/hooks) - WebSocket and state management hooks
- **Utility Libraries**: [audioinsight-ui/lib/](mdc:audioinsight-ui/lib) - Helper functions and utilities
- **Styling**: [audioinsight-ui/styles/](mdc:audioinsight-ui/styles) - Tailwind CSS and modern styling
- **Real-time progress tracking and results display with smooth updates**
- **Integration with backend via REST APIs and WebSockets**

### Infrastructure
- **Package Setup**: [pyproject.toml](mdc:pyproject.toml) - Modern Python package configuration
- **Startup Script**: [start.sh](mdc:start.sh) - Backend server startup
- **Environment**: [.env](mdc:.env) - Environment configuration
- **Dependencies**: [package.json](mdc:package.json) - Node.js dependencies and workspace coordination
- **Container Support**: [Dockerfile](mdc:Dockerfile) - Production-ready containerization
- **Documentation**: [README.md](mdc:README.md) & [TECHNICAL_DESCRIPTION.md](mdc:TECHNICAL_DESCRIPTION.md)

## Audio Processing Capabilities

### Transcription
- **Whisper-based speech-to-text** with LocalAgreement-2 streaming algorithms
- **Multiple model sizes** for accuracy vs speed tradeoffs (tiny, base, small, medium, large-v3-turbo)
- **Support for multiple audio formats** via FFmpeg integration
- **Real-time output** with smooth streaming
- **Context preservation** across streaming chunks for conversational coherence

### Speaker Diarization
- **Automatic speaker identification** using PyAnnote models
- **Real-time speaker switching detection** with timeline-based segments
- **Integration with transcription** for speaker-attributed text
- **Consistent speaker mapping** with stable speaker IDs

### Real-time Processing
- **Streaming audio processing** with LocalAgreement-2 policy for output stability
- **WebSocket-based live updates** with regular intervals
- **Progressive result delivery** as speech is recognized
- **Voice Activity Detection** for intelligent processing triggers
- **Simple LLM analysis** that integrates cleanly with transcription flow

### LLM-Powered Analysis (Simple Integration)
- **Direct async transcript processing** with simple text parsing
- **Background conversation analysis** with clean async patterns
- **Simple error handling** ensuring LLM failures don't affect transcription
- **Intelligent text processing** that operates with direct async calls
- **Configuration-based processing** with environment variable management

## Development Workflow

### Starting the Full Application
```bash
# Install Python package in development mode
pip install -e .

# Start both frontend and backend simultaneously
npm run dev
# Backend: http://localhost:8080
# Frontend: http://localhost:3030
```

### Individual Services
```bash
# Backend only
./start.sh
# Or: audioinsight-server

# Frontend only  
cd audioinsight-ui && npm run dev:frontend
```

### File Organization
- **Audio files** are processed from the `audio/` directory
- **Logs** are written to `logs/` directory with rotation support
- **Configuration** is managed via environment variables and [audioinsight/config.py](mdc:audioinsight/config.py)
- **Scripts** and utilities are located in `scripts/` directory
- **Backups** are stored in `backups/` directory

## Key Technologies

### Backend Technologies
- **FastAPI**: Modern Python web framework with automatic API documentation
- **Python**: Core language with type hints and async/await support
- **Whisper**: OpenAI's speech recognition model with LocalAgreement-2 streaming
- **PyTorch**: Deep learning framework for model execution
- **PyAnnote**: Speaker diarization and audio analysis
- **Pydantic**: Data validation and configuration management

### Frontend Technologies
- **Next.js**: React framework with App Router and modern features
- **React**: Component-based UI library with hooks and context
- **TypeScript**: Type-safe JavaScript with enhanced developer experience
- **Tailwind CSS**: Utility-first CSS framework for modern styling
- **shadcn/ui**: High-quality UI component library

### Audio Processing
- **librosa**: Audio analysis and signal processing
- **soundfile**: Audio file I/O operations
- **numpy**: Numerical computing for audio data
- **FFmpeg**: Audio format conversion and processing

### AI/ML Integration
- **OpenAI Whisper**: Speech-to-text transcription with multiple model sizes
- **PyAnnote**: Real-time speaker diarization and identification
- **Simple LLM integration**: Direct async conversation analysis and text enhancement
- **LocalAgreement-2**: Advanced streaming algorithm for output stability

### Infrastructure & Deployment
- **Docker**: Containerization with GPU support for production deployment
- **Environment-based configuration**: Secure configuration via environment variables
- **Simple async architecture**: Clean parallel processing patterns
- **Direct async processing**: Optimized resource utilization with standard patterns

### Processing & Performance
- **Simple async design**: Clean async/await patterns for all operations
- **Direct LLM calls**: Straightforward async processing for language models
- **Error isolation**: Simple error handling with recovery patterns
- **Efficient processing**: Optimized async operations for real-time performance

## API Architecture

### REST Endpoints
- **Configuration Management**: `/api/config/*` - Runtime configuration updates
- **Model Management**: `/api/models/*` - Model status and loading
- **LLM Integration**: `/api/llm/*` - LLM processing status and testing
- **Session Management**: `/cleanup-session`, `/cleanup-file` - Resource cleanup
- **Batch Processing**: `/api/batch/*` - Batch operation management

### WebSocket Communication
- **Real-time Transcription**: `/asr` - Unified live audio and file processing
- **Simple LLM Analysis**: Direct async analysis results via WebSocket
- **Progress Updates**: Regular update intervals for responsive feedback
- **Error Handling**: Graceful recovery with continued processing

### Processing Modes
- **Live Recording**: Direct browser microphone with real-time LLM analysis
- **File Upload + WebSocket**: Unified processing with real-time simulation
- **Direct File Processing**: Complete JSON response with LLM insights
- **Streaming File Processing**: Server-Sent Events with integrated analysis

## Performance Features

### Simple Architecture
- **Clean Async Processing**: Direct async/await patterns for all operations
- **Simple LLM Integration**: Straightforward async processing for language models
- **Efficient Resource Usage**: Optimized async operations for real-time performance
- **Configuration-Based Processing**: Environment-driven feature management

### Real-time Capabilities
- **LocalAgreement-2 Streaming**: Stable output through hypothesis validation
- **Regular Updates**: Consistent intervals for smooth display
- **Voice Activity Detection**: Intelligent processing triggers
- **Context Preservation**: Conversational coherence across chunks

### Fault Tolerance
- **Simple Error Handling**: Clean error recovery patterns
- **Graceful Degradation**: System continues operating during partial failures
- **Resource Cleanup**: Comprehensive session and file cleanup
- **Health Monitoring**: Basic status and performance tracking

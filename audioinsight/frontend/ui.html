<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AudioInsight</title>
    <style>
        body {
            font-family: ui-sans-serif, system-ui, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
            margin: 20px;
            text-align: center;
        }

        .main-container {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
        }

        .mode-selector {
            display: flex;
            gap: 10px;
            margin-bottom: 20px;
        }

        .mode-button {
            padding: 10px 20px;
            border: 2px solid #ddd;
            border-radius: 8px;
            background: white;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .mode-button.active {
            background: #007bff;
            color: white;
            border-color: #007bff;
        }

        .mode-button:hover {
            background: #f0f0f0;
        }

        .mode-button.active:hover {
            background: #0056b3;
        }

        .record-container,
        .upload-container {
            display: none;
        }

        .record-container.active,
        .upload-container.active {
            display: block;
        }

        /* Real-time toggle - DEPRECATED: Now both modes use unified WebSocket processing */
        .realtime-toggle {
            margin: 15px 0;
            display: none; /* Hidden since unified processing is always real-time */
            align-items: center;
            gap: 10px;
            justify-content: center;
        }

        .toggle-switch {
            position: relative;
            width: 50px;
            height: 24px;
            background: #ddd;
            border-radius: 12px;
            cursor: pointer;
            transition: background 0.3s;
        }

        .toggle-switch.active {
            background: #007bff;
        }

        .toggle-slider {
            position: absolute;
            top: 2px;
            left: 2px;
            width: 20px;
            height: 20px;
            background: white;
            border-radius: 50%;
            transition: transform 0.3s;
        }

        .toggle-switch.active .toggle-slider {
            transform: translateX(26px);
        }

        /* File Upload Styles */
        .upload-zone {
            border: 3px dashed #ddd;
            border-radius: 10px;
            padding: 40px;
            margin: 20px 0;
            background: #fafafa;
            cursor: pointer;
            transition: all 0.3s ease;
            max-width: 500px;
            margin: 20px auto;
        }

        .upload-zone:hover,
        .upload-zone.dragover {
            border-color: #007bff;
            background: #f0f8ff;
        }

        .upload-zone.processing {
            border-color: #28a745;
            background: #f0fff0;
        }

        .upload-icon {
            font-size: 48px;
            color: #999;
            margin-bottom: 10px;
        }

        .upload-text {
            font-size: 16px;
            color: #666;
            margin-bottom: 10px;
        }

        .upload-subtext {
            font-size: 14px;
            color: #999;
        }

        .file-input {
            display: none;
        }

        .file-info {
            margin-top: 15px;
            padding: 10px;
            background: #f8f9fa;
            border-radius: 5px;
            font-size: 14px;
            color: #666;
        }

        .progress-container {
            margin-top: 15px;
            display: none;
        }

        .progress-bar {
            width: 100%;
            height: 20px;
            background: #e9ecef;
            border-radius: 10px;
            overflow: hidden;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #007bff, #28a745);
            width: 0%;
            transition: width 0.3s ease;
        }

        .progress-text {
            margin-top: 5px;
            font-size: 12px;
            color: #666;
        }

        /* Recording Styles */
        #recordButton {
            width: 50px;
            height: 50px;
            border: none;
            border-radius: 50%;
            background-color: white;
            cursor: pointer;
            transition: all 0.3s ease;
            border: 1px solid rgb(233, 233, 233);
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
        }

        #recordButton.recording {
            width: 180px;
            border-radius: 40px;
            justify-content: flex-start;
            padding-left: 20px;
        }

        #recordButton:active {
            transform: scale(0.95);
        }

        .shape-container {
            width: 25px;
            height: 25px;
            display: flex;
            align-items: center;
            justify-content: center;
            flex-shrink: 0;
        }

        .shape {
            width: 25px;
            height: 25px;
            background-color: rgb(209, 61, 53);
            border-radius: 50%;
            transition: all 0.3s ease;
        }

        #recordButton:disabled .shape {
            background-color: #6e6d6d;
        }

        #recordButton.recording .shape {
            border-radius: 5px;
            width: 25px;
            height: 25px;
        }

        .recording-info {
            display: none;
            align-items: center;
            margin-left: 15px;
            flex-grow: 1;
        }

        #recordButton.recording .recording-info {
            display: flex;
        }

        .wave-container {
            width: 60px;
            height: 30px;
            position: relative;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        #waveCanvas {
            width: 100%;
            height: 100%;
        }

        .timer {
            font-size: 14px;
            font-weight: 500;
            color: #333;
            margin-left: 10px;
        }

        #status {
            margin-top: 20px;
            font-size: 16px;
            color: #333;
        }

        .settings-container {
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 15px;
            margin-top: 20px;
        }

        .settings {
            display: flex;
            flex-direction: column;
            align-items: flex-start;
            gap: 5px;
        }

        #chunkSelector,
        #websocketInput {
            font-size: 16px;
            padding: 5px;
            border-radius: 5px;
            border: 1px solid #ddd;
            background-color: #ffffff;
            max-height: 30px;
        }

        #websocketInput {
            width: 200px;
        }

        #chunkSelector:focus,
        #websocketInput:focus {
            outline: none;
            border-color: #007bff;
        }

        label {
            font-size: 14px;
        }

        /* Speaker-labeled transcript area */
        #linesTranscript {
            margin: 20px auto;
            max-width: 700px;
            text-align: left;
            font-size: 16px;
        }

        #linesTranscript p {
            margin: 0px 0;
        }

        #linesTranscript strong {
            color: #333;
        }

        #speaker {
            border: 1px solid rgb(229, 229, 229);
            border-radius: 100px;
            padding: 2px 10px;
            font-size: 14px;
            margin-bottom: 0px;
        }
        .label_diarization {
            background-color: #ffffff66;
            border-radius: 8px 8px 8px 8px;
            padding: 2px 10px;
            margin-left: 10px;
            display: inline-block;
            white-space: nowrap;
            font-size: 14px;
            margin-bottom: 0px;
            color: rgb(134, 134, 134)
        }

        .label_transcription {
            background-color: #ffffff66;
            border-radius: 8px 8px 8px 8px;
            padding: 2px 10px;
            display: inline-block;
            white-space: nowrap;
            margin-left: 10px;
            font-size: 14px;
            margin-bottom: 0px;
            color: #000000
        }

        #timeInfo {
            color: #666;
            margin-left: 10px;
        }

        .textcontent {
            font-size: 16px;
            padding-left: 10px;
            margin-bottom: 10px;
            margin-top: 1px;
            padding-top: 5px;
            border-radius: 0px 0px 0px 10px;
        }

        .buffer_diarization {
            color: rgb(134, 134, 134);
            margin-left: 4px;
        }

        .buffer_transcription {
            color: #7474748c;
            margin-left: 4px;
        }

        .spinner {
            display: inline-block;
            width: 8px;
            height: 8px;
            border: 2px solid #8d8d8d5c;
            border-top: 2px solid #6c6c6ce5;
            border-radius: 50%;
            animation: spin 0.6s linear infinite;
            vertical-align: middle;
            margin-bottom: 2px;
            margin-right: 5px;
        }

        @keyframes spin {
            to {
                transform: rotate(360deg);
            }
        }

        .silence {
            color: #666;
            background-color: #f3f3f3;
            font-size: 13px;
            border-radius: 30px;
            padding: 2px 10px;
        }

        .loading {
            color: #666;
            background-color: #ff4d4d0f;
            border-radius: 8px 8px 8px 0px;
            padding: 2px 10px;
            font-size: 14px;
            margin-bottom: 0px;
        }

        /* Summaries styling */
        .summaries-container {
            margin: 20px auto;
            max-width: 700px;
            text-align: left;
        }

        .summary {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 8px;
            padding: 15px;
            margin-bottom: 15px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }

        .summary p {
            margin: 8px 0;
            line-height: 1.4;
        }

        .summary strong {
            color: #495057;
            font-weight: 600;
        }

        .summary-header {
            font-size: 16px;
            font-weight: bold;
            color: #007bff;
            margin-bottom: 10px;
            border-bottom: 1px solid #e9ecef;
            padding-bottom: 5px;
        }
    </style>
</head>

<body>
    <div class="main-container">
        <!-- Mode selector -->
        <div class="mode-selector">
            <button class="mode-button active" id="recordMode">üé§ Live Recording</button>
            <button class="mode-button" id="uploadMode">üìÅ Upload File</button>
        </div>

        <!-- Recording container -->
        <div class="record-container active">
    <div class="settings-container">
        <button id="recordButton">
            <div class="shape-container">
                <div class="shape"></div>
            </div>
            <div class="recording-info">
                <div class="wave-container">
                    <canvas id="waveCanvas"></canvas>
                </div>
                <div class="timer">00:00</div>
            </div>
        </button>
        <div class="settings">
            <div>
                <label for="chunkSelector">Chunk size (ms):</label>
                <select id="chunkSelector">
                    <option value="500">500 ms</option>
                    <option value="1000" selected>1000 ms</option>
                    <option value="2000">2000 ms</option>
                    <option value="3000">3000 ms</option>
                    <option value="4000">4000 ms</option>
                    <option value="5000">5000 ms</option>
                </select>
            </div>
            <div>
                <label for="websocketInput">WebSocket URL:</label>
                <input id="websocketInput" type="text" />
                    </div>
            </div>
        </div>
    </div>

        <!-- Upload container -->
        <div class="upload-container">
            <div class="realtime-toggle">
                <span>Show results in real-time</span>
                <div class="toggle-switch" id="realtimeToggle">
                    <div class="toggle-slider"></div>
                </div>
            </div>

            <div class="upload-zone" id="uploadZone">
                <div class="upload-icon">üéµ</div>
                <div class="upload-text">Drag & drop an audio file here</div>
                <div class="upload-subtext">or click to browse files</div>
                <div class="upload-subtext">Supports: MP3, MP4, WAV, M4A, FLAC, OGG</div>
                <input type="file" id="fileInput" class="file-input" accept="audio/*">
            </div>
            
            <div class="file-info" id="fileInfo" style="display: none;"></div>
            
            <div class="progress-container" id="progressContainer">
                <div class="progress-bar">
                    <div class="progress-fill" id="progressFill"></div>
                </div>
                <div class="progress-text" id="progressText">Processing...</div>
            </div>
        </div>

        <!-- Status and transcript -->
        <p id="status"></p>
        <!-- Summaries will be displayed here -->
        <div id="summaries" class="summaries-container"></div>
    <div id="linesTranscript"></div>
    </div>

    <script>
        // Global variables
        let isRecording = false;
        let websocket = null;
        let recorder = null;
        let chunkDuration = 1000;
        let websocketUrl = "ws://localhost:8001/asr";
        let userClosing = false;
        let startTime = null;
        let timerInterval = null;
        let audioContext = null;
        let analyser = null;
        let microphone = null;
        let waveCanvas = document.getElementById("waveCanvas");
        let waveCtx = waveCanvas.getContext("2d");
        let animationFrame = null;
        let waitingForStop = false;
        let lastReceivedData = null;
        
        // File upload variables
        let isProcessingFile = false;
        let currentMode = 'record'; // 'record' or 'upload'
        let realtimeMode = true; // Real-time display mode
        let uploadResults = []; // Store upload results for real-time display
        
        // Initialize canvas
        waveCanvas.width = 60 * (window.devicePixelRatio || 1);
        waveCanvas.height = 30 * (window.devicePixelRatio || 1);
        waveCtx.scale(window.devicePixelRatio || 1, window.devicePixelRatio || 1);

        // DOM elements
        const statusText = document.getElementById("status");
        const recordButton = document.getElementById("recordButton");
        const chunkSelector = document.getElementById("chunkSelector");
        const websocketInput = document.getElementById("websocketInput");
        const linesTranscriptDiv = document.getElementById("linesTranscript");
        const summariesDiv = document.getElementById("summaries");
        const timerElement = document.querySelector(".timer");

        // Mode switching elements
        const recordMode = document.getElementById("recordMode");
        const uploadMode = document.getElementById("uploadMode");
        const recordContainer = document.querySelector(".record-container");
        const uploadContainer = document.querySelector(".upload-container");
        
        // File upload elements
        const uploadZone = document.getElementById("uploadZone");
        const fileInput = document.getElementById("fileInput");
        const fileInfo = document.getElementById("fileInfo");
        const progressContainer = document.getElementById("progressContainer");
        const progressFill = document.getElementById("progressFill");
        const progressText = document.getElementById("progressText");
        const realtimeToggle = document.getElementById("realtimeToggle");

        // WebSocket configuration
        const host = window.location.hostname || "localhost";
        const port = window.location.port || "8001";
        const protocol = window.location.protocol === "https:" ? "wss" : "ws";
        const defaultWebSocketUrl = `${protocol}://${host}:${port}/asr`;
        websocketInput.value = defaultWebSocketUrl;
        websocketUrl = defaultWebSocketUrl;

        // Mode switching
        recordMode.addEventListener("click", () => switchMode('record'));
        uploadMode.addEventListener("click", () => switchMode('upload'));

        function switchMode(mode) {
            currentMode = mode;
            
            // Update button states
            recordMode.classList.toggle('active', mode === 'record');
            uploadMode.classList.toggle('active', mode === 'upload');
            
            // Update container visibility
            recordContainer.classList.toggle('active', mode === 'record');
            uploadContainer.classList.toggle('active', mode === 'upload');
            
            // Reset state when switching modes
            if (isRecording) stopRecording();
            if (isProcessingFile) {
                // Reset file processing
                isProcessingFile = false;
                uploadZone.classList.remove('processing');
                progressContainer.style.display = 'none';
            }
            
            // Clear transcript and status
            linesTranscriptDiv.innerHTML = '';
            // Don't clear summaries when switching modes - they should persist
            statusText.textContent = mode === 'record' ? 
                "Click to start transcription" : 
                "Select or drag an audio file to transcribe";
        }

        // Settings event listeners
        chunkSelector.addEventListener("change", () => {
            chunkDuration = parseInt(chunkSelector.value);
        });

        websocketInput.addEventListener("change", () => {
            const urlValue = websocketInput.value.trim();
            if (!urlValue.startsWith("ws://") && !urlValue.startsWith("wss://")) {
                statusText.textContent = "Invalid WebSocket URL (must start with ws:// or wss://)";
                return;
            }
            websocketUrl = urlValue;
            statusText.textContent = "WebSocket URL updated. Ready to connect.";
        });

        // File upload event listeners
        uploadZone.addEventListener('click', () => fileInput.click());
        uploadZone.addEventListener('dragover', handleDragOver);
        uploadZone.addEventListener('dragleave', handleDragLeave);
        uploadZone.addEventListener('drop', handleDrop);
        fileInput.addEventListener('change', handleFileSelect);
        realtimeToggle.addEventListener('click', toggleRealtimeMode);

        function handleDragOver(e) {
            e.preventDefault();
            uploadZone.classList.add('dragover');
        }

        function handleDragLeave(e) {
            e.preventDefault();
            uploadZone.classList.remove('dragover');
        }

        function handleDrop(e) {
            e.preventDefault();
            uploadZone.classList.remove('dragover');
            const files = e.dataTransfer.files;
            if (files.length > 0) {
                processFile(files[0]);
            }
        }

        function handleFileSelect(e) {
            const files = e.target.files;
            if (files.length > 0) {
                processFile(files[0]);
            }
        }

        function toggleRealtimeMode() {
            realtimeMode = !realtimeMode;
            realtimeToggle.classList.toggle('active', realtimeMode);
        }

        // Initialize real-time mode as active
        realtimeToggle.classList.add('active');

        // Process uploaded file using unified WebSocket approach
        async function processFile(file) {
            if (isProcessingFile) return;
            
            isProcessingFile = true;
            uploadZone.classList.add('processing');
            progressContainer.style.display = 'block';
            progressFill.style.width = '0%';
            
            // Clear previous transcription
            linesTranscriptDiv.innerHTML = '';
            uploadResults = [];
            
            // Show file info
            fileInfo.style.display = 'block';
            fileInfo.textContent = `Selected: ${file.name} (${(file.size / 1024 / 1024).toFixed(2)} MB)`;
            
            // Always use unified WebSocket processing for consistency
            await processFileUnified(file);
        }

        // Process file using unified WebSocket approach (same as live recording)
        async function processFileUnified(file) {
            try {
                statusText.textContent = "Uploading file...";
                progressText.textContent = "Preparing file for processing...";
                
                // Step 1: Upload file to server
                const formData = new FormData();
                formData.append('file', file);
                
                const uploadResponse = await fetch('/upload-file', {
                    method: 'POST',
                    body: formData
                });
                
                if (!uploadResponse.ok) {
                    const errorData = await uploadResponse.json();
                    throw new Error(errorData.detail || `Upload failed (${uploadResponse.status})`);
                }
                
                const uploadResult = await uploadResponse.json();
                const { file_path, duration, filename } = uploadResult;
                
                statusText.textContent = `Processing ${filename} (${duration.toFixed(1)}s)...`;
                progressText.textContent = "Connecting to WebSocket...";
                
                // Step 2: Connect to WebSocket (same as live recording)
                if (websocket && websocket.readyState === WebSocket.OPEN) {
                    // Already connected, proceed with file processing
                    await processFileViaWebSocket(file_path, duration, filename);
                } else {
                    // Need to establish WebSocket connection first
                    console.log("Connecting to WebSocket for file processing");
                    await setupWebSocket();
                    await processFileViaWebSocket(file_path, duration, filename);
                }
                
            } catch (error) {
                console.error("Error in unified file processing:", error);
                handleUploadError(error.message);
            }
        }

        // Process file through WebSocket connection (identical to live recording pipeline)
        async function processFileViaWebSocket(filePath, duration, filename) {
            try {
                progressText.textContent = "Processing via WebSocket...";
                
                // Send file processing request through WebSocket (same as live recording)
                const fileMessage = {
                    type: "file_upload",
                    file_path: filePath,
                    duration: duration,
                    filename: filename
                };
                
                if (websocket && websocket.readyState === WebSocket.OPEN) {
                    websocket.send(JSON.stringify(fileMessage));
                    statusText.textContent = `Processing file through unified pipeline...`;
                    progressText.textContent = "Receiving real-time transcription...";
                } else {
                    throw new Error("WebSocket connection not available");
                }
                
                // The transcription results will come through the same WebSocket message handler
                // as live recording, ensuring identical processing behavior
                
            } catch (error) {
                console.error("Error processing file via WebSocket:", error);
                handleUploadError(error.message);
            }
        }

        // Process file with real-time streaming using Server-Sent Events (DEPRECATED - keeping for backward compatibility)
        async function processFileRealtime(file) {
            try {
                statusText.textContent = "Starting real-time transcription...";
                progressText.textContent = "Connecting to streaming endpoint...";
                
                // Create FormData for file upload
                const formData = new FormData();
                formData.append('file', file);
                
                // Use fetch to start the streaming upload
                const response = await fetch('/upload-stream', {
                    method: 'POST',
                    body: formData
                });
                
                if (!response.ok) {
                    throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                }
                
                // Create a reader for the stream
                const reader = response.body.getReader();
                const decoder = new TextDecoder();
                let buffer = '';
                let currentLines = [];
                
                statusText.textContent = "Receiving real-time transcription...";
                
                while (true) {
                    const { done, value } = await reader.read();
                    
                    if (done) break;
                    
                    // Decode the chunk and add to buffer
                    buffer += decoder.decode(value, { stream: true });
                    
                    // Process complete SSE events
                    const events = buffer.split('\n\n');
                    buffer = events.pop(); // Keep incomplete event in buffer
                    
                    for (const event of events) {
                        if (event.trim()) {
                            processSSEEvent(event, currentLines);
                        }
                    }
                }
                
                // Process any remaining event in buffer
                if (buffer.trim()) {
                    processSSEEvent(buffer, currentLines);
                }
                
            } catch (error) {
                console.error("Error in real-time processing:", error);
                handleUploadError(error.message);
            }
        }

        // Process SSE events from the streaming endpoint
        function processSSEEvent(eventText, currentLines) {
            const lines = eventText.split('\n');
            let eventType = '';
            let eventData = '';
            
            for (const line of lines) {
                if (line.startsWith('event: ')) {
                    eventType = line.substring(7);
                } else if (line.startsWith('data: ')) {
                    eventData = line.substring(6);
                }
            }
            
            if (!eventType || !eventData) return;
            
            try {
                const data = JSON.parse(eventData);
                
                switch (eventType) {
                    case 'start':
                        statusText.textContent = `Processing ${data.filename} (${data.duration.toFixed(1)}s)...`;
                        progressText.textContent = "Real-time transcription starting...";
                        break;
                        
                    case 'transcription':
                        // Add new transcription segment in real-time
                        if (data.text && data.text.trim()) {
                            const newSegment = {
                                text: data.text,
                                speaker: data.lines && data.lines[0] ? data.lines[0].speaker : 1,
                                beg: currentLines.length * 5, // Approximate timing
                                end: (currentLines.length + 1) * 5
                            };
                            currentLines.push(newSegment);
                            
                            // Update display immediately with new segment
                            renderLinesWithBuffer(
                                currentLines.slice(), // Current completed lines
                                "", // No diarization buffer for uploads
                                data.buffer || "", // Current buffer
                                0, 0, false // Not finalizing
                            );
                        }
                        break;
                        
                    case 'progress':
                        const progressPercent = (data.progress / data.total) * 100;
                        progressFill.style.width = `${progressPercent}%`;
                        progressText.textContent = `Processing: ${data.progress.toFixed(1)}s / ${data.total.toFixed(1)}s`;
                        break;
                        
                    case 'complete':
                        progressFill.style.width = '100%';
                        progressText.textContent = "Real-time transcription complete!";
                        statusText.textContent = "File processed successfully in real-time!";
                        
                        // Final render to clean up any remaining buffer content
                        renderLinesWithBuffer(currentLines, "", "", 0, 0, true);
                        
                        setTimeout(() => {
                            isProcessingFile = false;
                            uploadZone.classList.remove('processing');
                            progressContainer.style.display = 'none';
                        }, 2000);
                        break;
                        
                    case 'error':
                        handleUploadError(data.error || 'Unknown streaming error');
                        break;
                }
                
            } catch (e) {
                console.warn('Failed to parse SSE event data:', eventData, e);
            }
        }

        // Process file for instant results (original implementation)
        async function processFileInstant(file) {
            try {
                statusText.textContent = "Uploading and processing file...";
                progressText.textContent = "Uploading file...";
                
                // Create FormData for file upload
                const formData = new FormData();
                formData.append('file', file);
                
                // Upload file to server with progress tracking
                const xhr = new XMLHttpRequest();
                
                // Track upload progress
                xhr.upload.addEventListener('progress', (e) => {
                    if (e.lengthComputable) {
                        const percentComplete = (e.loaded / e.total) * 100;
                        progressFill.style.width = `${percentComplete}%`;
                        progressText.textContent = `Uploading: ${Math.round(percentComplete)}%`;
                    }
                });
                
                // Handle response
                xhr.onload = function() {
                    if (xhr.status === 200) {
                        try {
                            const result = JSON.parse(xhr.responseText);
                            handleUploadSuccess(result);
                        } catch (e) {
                            console.error('Error parsing response:', e);
                            handleUploadError('Invalid response from server');
                        }
                    } else {
                        try {
                            const error = JSON.parse(xhr.responseText);
                            handleUploadError(error.detail || `Upload failed (${xhr.status})`);
                        } catch (e) {
                            handleUploadError(`Upload failed (${xhr.status})`);
                        }
                    }
                };
                
                xhr.onerror = function() {
                    handleUploadError('Network error during upload');
                };
                
                // Send the request
                xhr.open('POST', '/upload');
                xhr.send(formData);
                
            } catch (error) {
                console.error("Error processing file:", error);
                handleUploadError(error.message);
            }
        }
        
        function handleUploadSuccess(result) {
            progressFill.style.width = '100%';
            progressText.textContent = "Processing complete!";
            statusText.textContent = "File processed successfully!";
            
            // Store results for processing
            uploadResults = result.transcription || [];
            
            // Display all results immediately (instant mode)
            displayAllResults();
            
            setTimeout(() => {
                isProcessingFile = false;
                uploadZone.classList.remove('processing');
                progressContainer.style.display = 'none';
            }, 2000);
        }

        function displayAllResults() {
            if (uploadResults.length > 0) {
                // Convert server response to the format expected by renderLinesWithBuffer
                const lines = uploadResults.map((segment, index) => ({
                    text: segment.text,
                    speaker: segment.lines && segment.lines[0] ? segment.lines[0].speaker : 1,
                    beg: index * 5, // Approximate timing - 5 second segments
                    end: (index + 1) * 5
                }));
                
                // Render all transcription at once
                renderLinesWithBuffer(lines, "", "", 0, 0, true);
            }
        }
        
        function handleUploadError(errorMessage) {
            statusText.textContent = `Error processing file: ${errorMessage}`;
            isProcessingFile = false;
            uploadZone.classList.remove('processing');
            progressContainer.style.display = 'none';
        }

        // WebSocket setup function (same as original)
        function setupWebSocket() {
            return new Promise((resolve, reject) => {
                try {
                    websocket = new WebSocket(websocketUrl);
                } catch (error) {
                    statusText.textContent = "Invalid WebSocket URL. Please check and try again.";
                    reject(error);
                    return;
                }

                websocket.onopen = () => {
                    statusText.textContent = "Connected to server.";
                    resolve();
                };

                websocket.onclose = () => {
                    if (userClosing) {
                        if (waitingForStop) {
                            statusText.textContent = "Processing finalized or connection closed.";
                            if (lastReceivedData) {
                                renderLinesWithBuffer(
                                    lastReceivedData.lines || [],
                                    lastReceivedData.buffer_diarization || "",
                                    lastReceivedData.buffer_transcription || "",
                                    0, 0, true // isFinalizing = true
                                );
                            }
                        }
                    } else {
                        statusText.textContent = "Disconnected from the WebSocket server. (Check logs if model is loading.)";
                        if (isRecording) {
                            stopRecording(); 
                        }
                    }
                    isRecording = false;  
                    waitingForStop = false; 
                    userClosing = false;  
                    lastReceivedData = null;  
                    websocket = null;    
                    updateUI();  
                };

                websocket.onerror = () => {
                    statusText.textContent = "Error connecting to WebSocket.";
                    reject(new Error("Error connecting to WebSocket"));
                };

                // Handle messages from server
                websocket.onmessage = (event) => {
                    const data = JSON.parse(event.data);
                    
                    // Check for status messages
                    if (data.type === "ready_to_stop") {
                        console.log("Ready to stop received, finalizing display and closing WebSocket.");
                        waitingForStop = false;

                        if (lastReceivedData) {
                            renderLinesWithBuffer(
                                lastReceivedData.lines || [],
                                lastReceivedData.buffer_diarization || "",
                                lastReceivedData.buffer_transcription || "",
                                0, // No more lag
                                0, // No more lag
                                true // isFinalizing = true
                            );
                        }
                        
                        // Handle completion for both live recording and file upload
                        if (isProcessingFile) {
                            // File upload completed
                            progressFill.style.width = '100%';
                            progressText.textContent = "File processing complete!";
                            statusText.textContent = "File processed successfully through unified pipeline!";
                            
                            setTimeout(() => {
                                isProcessingFile = false;
                                uploadZone.classList.remove('processing');
                                progressContainer.style.display = 'none';
                            }, 2000);
                        } else {
                            // Live recording completed
                            statusText.textContent = "Finished processing audio! Ready to record again.";
                            recordButton.disabled = false;
                        }
                        
                        if (websocket) {
                            websocket.close(); // will trigger onclose
                        }
                        return;
                    }
                    
                    // Check for error messages
                    if (data.type === "error") {
                        console.error("WebSocket error received:", data.error);
                        if (isProcessingFile) {
                            handleUploadError(data.error || 'Unknown error during file processing');
                        } else {
                            statusText.textContent = `Error: ${data.error}`;
                        }
                        return;
                    }
                    
                    lastReceivedData = data; 
                    
                    // Render summaries if provided
                    if (data.summaries && data.summaries.length > 0) {
                        console.log("üìù Rendering summaries:", data.summaries);
                        const summaryTime = new Date(data.summaries[0].timestamp * 1000).toLocaleTimeString();
                        summariesDiv.innerHTML = data.summaries.map((s, index) => `
                            <div class="summary">
                                <div class="summary-header">üìù AI Summary ${index + 1} (${summaryTime})</div>
                                <p><strong>Summary:</strong> ${s.summary}</p>
                                <p><strong>Key Points:</strong> ${s.key_points.join(" ‚Ä¢ ")}</p>
                                <p><strong>Text Length:</strong> ${s.text_length} characters</p>
                            </div>
                        `).join("");
                        
                        // Scroll summaries into view
                        summariesDiv.scrollIntoView({ behavior: 'smooth', block: 'nearest' });
                    }
                    
                    // Handle normal transcription updates (same for both live and file upload)
                    const { 
                        lines = [], 
                        buffer_transcription = "", 
                        buffer_diarization = "",
                        remaining_time_transcription = 0,
                        remaining_time_diarization = 0
                    } = data;
                    
                    renderLinesWithBuffer(
                        lines, 
                        buffer_diarization, 
                        buffer_transcription, 
                        remaining_time_diarization,
                        remaining_time_transcription,
                        false // isFinalizing = false for normal updates
                    );
                };
            });
        }

        // Render transcript function (same as original)
        function renderLinesWithBuffer(lines, buffer_diarization, buffer_transcription, remaining_time_diarization, remaining_time_transcription, isFinalizing = false) {
            const linesHtml = lines.map((item, idx) => {
                let timeInfo = "";
                if (item.beg !== undefined && item.end !== undefined) {
                    timeInfo = ` ${item.beg} - ${item.end}`;
                }

                let speakerLabel = "";
                if (item.speaker === -2) {
                    speakerLabel = `<span class="silence">Silence<span id='timeInfo'>${timeInfo}</span></span>`;
                } else if (item.speaker == -1) {
                    speakerLabel = `<span id="speaker">Speaker 1<span id='timeInfo'>${timeInfo}</span></span>`;
                } else if (item.speaker >= 0) {
                    // Add 1 to speaker number so speaker 0 becomes "Speaker 1", speaker 1 becomes "Speaker 2", etc.
                    const displaySpeaker = item.speaker + 1;
                    speakerLabel = `<span id="speaker">Speaker ${displaySpeaker}<span id='timeInfo'>${timeInfo}</span></span>`;
                    
                    // Add processing indicator for speaker 0 when still processing
                    if (item.speaker == 0 && !isFinalizing && remaining_time_diarization > 0) {
                        speakerLabel += `<span class='loading'><span class="spinner"></span><span id='timeInfo'>${remaining_time_diarization} second(s) of audio are undergoing diarization</span></span>`;
                    }
                }

                let currentLineText = item.text || "";

                if (idx === lines.length - 1) { 
                    if (!isFinalizing) {
                        if (remaining_time_transcription > 0) {
                             speakerLabel += `<span class="label_transcription"><span class="spinner"></span>Transcription lag <span id='timeInfo'>${remaining_time_transcription}s</span></span>`;
                        }
                        if (buffer_diarization && remaining_time_diarization > 0) {
                             speakerLabel += `<span class="label_diarization"><span class="spinner"></span>Diarization lag<span id='timeInfo'>${remaining_time_diarization}s</span></span>`;
                        }
                    }

                    if (buffer_diarization) {
                        if (isFinalizing) {
                            currentLineText += (currentLineText.length > 0 && buffer_diarization.trim().length > 0 ? " " : "") + buffer_diarization.trim();
                        } else {
                            currentLineText += `<span class="buffer_diarization">${buffer_diarization}</span>`;
                        }
                    }
                    if (buffer_transcription) {
                        if (isFinalizing) {
                            currentLineText += (currentLineText.length > 0 && buffer_transcription.trim().length > 0 ? " " : "") + buffer_transcription.trim();
                        } else {
                            currentLineText += `<span class="buffer_transcription">${buffer_transcription}</span>`;
                        }
                    }
                }
                
                return currentLineText.trim().length > 0 || speakerLabel.length > 0
                    ? `<p>${speakerLabel}<br/><div class='textcontent'>${currentLineText}</div></p>`
                    : `<p>${speakerLabel}<br/></p>`; 
            }).join("");

            linesTranscriptDiv.innerHTML = linesHtml;
        }

        // Timer and visualization functions (same as original)
        function updateTimer() {
            if (!startTime) return;
            
            const elapsed = Math.floor((Date.now() - startTime) / 1000);
            const minutes = Math.floor(elapsed / 60).toString().padStart(2, "0");
            const seconds = (elapsed % 60).toString().padStart(2, "0");
            timerElement.textContent = `${minutes}:${seconds}`;
        }

        function drawWaveform() {
            if (!analyser) return;
            
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            analyser.getByteTimeDomainData(dataArray);
            
            waveCtx.clearRect(0, 0, waveCanvas.width / (window.devicePixelRatio || 1), waveCanvas.height / (window.devicePixelRatio || 1));
            waveCtx.lineWidth = 1;
            waveCtx.strokeStyle = 'rgb(0, 0, 0)';
            waveCtx.beginPath();
            
            const sliceWidth = (waveCanvas.width / (window.devicePixelRatio || 1)) / bufferLength;
            let x = 0;
            
            for (let i = 0; i < bufferLength; i++) {
                const v = dataArray[i] / 128.0;
                const y = v * (waveCanvas.height / (window.devicePixelRatio || 1)) / 2;
                
                if (i === 0) {
                    waveCtx.moveTo(x, y);
                } else {
                    waveCtx.lineTo(x, y);
                }
                
                x += sliceWidth;
            }
            
            waveCtx.lineTo(waveCanvas.width / (window.devicePixelRatio || 1), waveCanvas.height / (window.devicePixelRatio || 1) / 2);
            waveCtx.stroke();
            
            animationFrame = requestAnimationFrame(drawWaveform);
        }

        // Recording functions (same as original)
        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                microphone = audioContext.createMediaStreamSource(stream);
                microphone.connect(analyser);
                
                recorder = new MediaRecorder(stream, { mimeType: "audio/webm" });
                recorder.ondataavailable = (e) => {
                    if (websocket && websocket.readyState === WebSocket.OPEN) {
                        websocket.send(e.data);
                    }
                };
                recorder.start(chunkDuration);
                
                startTime = Date.now();
                timerInterval = setInterval(updateTimer, 1000);
                drawWaveform();
                
                isRecording = true;
                updateUI();
            } catch (err) {
                statusText.textContent = "Error accessing microphone. Please allow microphone access.";
                console.error(err);
            }
        }

        async function stopRecording() {
            userClosing = true;
            waitingForStop = true;
            
            if (websocket && websocket.readyState === WebSocket.OPEN) {
                // Send empty audio buffer as stop signal
                const emptyBlob = new Blob([], { type: 'audio/webm' });
                websocket.send(emptyBlob);
                statusText.textContent = "Recording stopped. Processing final audio...";
            }
            
            if (recorder) {
                recorder.stop();
                recorder = null;
            }
            
            if (microphone) {
                microphone.disconnect();
                microphone = null;
            }
            
            if (analyser) {
                analyser = null;
            }
            
            if (audioContext && audioContext.state !== 'closed') {
                try {
                    audioContext.close();
                } catch (e) {
                    console.warn("Could not close audio context:", e);
                }
                audioContext = null;
            }
            
            if (animationFrame) {
                cancelAnimationFrame(animationFrame);
                animationFrame = null;
            }
            
            if (timerInterval) {
                clearInterval(timerInterval);
                timerInterval = null;
            }            
            timerElement.textContent = "00:00";
            startTime = null;
            
            isRecording = false;
            updateUI();	
        }

        async function toggleRecording() {
            if (!isRecording) {
                if (waitingForStop) {
                    console.log("Waiting for stop, early return");
                    return;
                }
                console.log("Connecting to WebSocket");
                try {
                    if (websocket && websocket.readyState === WebSocket.OPEN) {
                        await startRecording();
                    } else {
                        await setupWebSocket();
                        await startRecording();
                    }
                } catch (err) {
                    statusText.textContent = "Could not connect to WebSocket or access mic. Aborted.";
                    console.error(err);
                }
            } else {
                console.log("Stopping recording");
                stopRecording();
            }
        }

        function updateUI() {
            recordButton.classList.toggle("recording", isRecording);
            recordButton.disabled = waitingForStop;

            if (waitingForStop) {
                if (statusText.textContent !== "Recording stopped. Processing final audio...") {
                     statusText.textContent = "Please wait for processing to complete...";
                }
            } else if (isRecording) {
                statusText.textContent = "Recording...";
            } else {
                if (statusText.textContent !== "Finished processing audio! Ready to record again." &&
                    statusText.textContent !== "Processing finalized or connection closed.") {
                    statusText.textContent = "Click to start transcription";
                }
            }
            if (!waitingForStop) {
                recordButton.disabled = false;
            }
        }

        // Event listeners
        recordButton.addEventListener("click", toggleRecording);
        
        // Initialize
        statusText.textContent = "Click to start transcription";
    </script>
</body>

</html>
